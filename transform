from transformers import PegasusForConditionalGeneration, PegasusTokenizer

# Load the pre-trained Pegasus model and tokenizer
model_name = 'google/pegasus-xsum'
tokenizer = PegasusTokenizer.from_pretrained(model_name)
model = PegasusForConditionalGeneration.from_pretrained(model_name)

# Tokenize and encode the text
text = "This is a long piece of text that needs to be summarized."
inputs = tokenizer(text, truncation=True, padding='longest', return_tensors='pt')

# Generate the summary
summary_ids = model.generate(inputs['input_ids'], num_beams=4, max_length=100, early_stopping=True)
summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)

print("Summary:", summary)
